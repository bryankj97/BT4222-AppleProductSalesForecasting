{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zywmH0u2v9ZW",
    "outputId": "c40f96ef-a2df-4b89-b071-c782bda29d7a"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#load data to Google Drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IAKLkAkRwVTi"
   },
   "outputs": [],
   "source": [
    "#path = 'gdrive/My Drive/BT4222/data/twitter_train.csv'\n",
    "df = pd.read_csv('./twitter_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "knFXsh68wisk",
    "outputId": "6f0ea9a0-d80f-456e-e7a1-de2012585db4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                       my boss is bullying me...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "XfLb-S2_xw_A",
    "outputId": "aee33d47-580e-4d7a-a0ae-9d04dd90cbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "Uem9353Uxzov",
    "outputId": "2000ecce-0844-48ac-f729-9f343b47d668"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>fdb77c3752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID text selected_text sentiment\n",
       "314  fdb77c3752  NaN           NaN   neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JR-QGQ9ix1Cs"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LU2vYT48yE9p",
    "outputId": "5297ac2b-7c41-4d18-960c-16c279397703"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the only NaN row\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s077hBm2yNtc",
    "outputId": "0289b9eb-c766-463e-a2bc-5f332bed09e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if all rows are non-null\n",
    "len(df[df.isnull().any(axis=1)]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJHW1X9ayQEX",
    "outputId": "5fd3cab5-c6dc-49fb-bf68-a633c5292712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11117\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-E5RlwdbyU6o"
   },
   "outputs": [],
   "source": [
    "# Encode snetiment with numerics\n",
    "def encode_sentiment(x):\n",
    "  if x == 'positive':\n",
    "    return 1\n",
    "  elif x == 'negative':\n",
    "    return -1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HRRHiPBMydyU"
   },
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].apply(encode_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "ykqGHd_FyimR",
    "outputId": "3a3ec7ea-664a-4089-8a7f-85b942c5c214"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                       my boss is bullying me...   \n",
       "\n",
       "                         selected_text  sentiment  \n",
       "0  I`d have responded, if I were going          0  \n",
       "1                             Sooo SAD         -1  \n",
       "2                          bullying me         -1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kUyJh1nnzlDy"
   },
   "outputs": [],
   "source": [
    "obs_num = min(df['sentiment'].value_counts())\n",
    "\n",
    "df_class_positive = df[df['sentiment'] == 1]\n",
    "df_class_neutral = df[df['sentiment'] == 0]\n",
    "df_class_negative = df[df['sentiment'] == -1]\n",
    "\n",
    "sample_positive = df_class_positive.sample(obs_num)\n",
    "sample_neutral = df_class_neutral.sample(obs_num)\n",
    "sample_negative = df_class_negative.sample(obs_num)\n",
    "\n",
    "#Concat and shuffle\n",
    "df_new = pd.concat([sample_positive, sample_neutral, sample_negative], axis=0).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlP95Wbuz9q9",
    "outputId": "cd0c99ec-6c13-4da3-e835-aeb972f1c7c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    7781\n",
       " 1    7781\n",
       " 0    7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fKfNln2h0HIk"
   },
   "outputs": [],
   "source": [
    "X_train = df_new.text\n",
    "y_train = df_new.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gCsKuBmq0S_I"
   },
   "outputs": [],
   "source": [
    "#path_test = 'gdrive/My Drive/BT4222/data/twitter_test.csv'\n",
    "df_test = pd.read_csv('./twitter_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3Svtg8uo0Xxu"
   },
   "outputs": [],
   "source": [
    "df_test['sentiment'] = df_test['sentiment'].apply(encode_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QYGJyypG0keg"
   },
   "outputs": [],
   "source": [
    "X_test = df_test.text\n",
    "y_test = df_test.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yno1dSOi0q6x",
    "outputId": "30933b1e-3d88-4c59-98ca-d585d92ea1e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23343,)\n",
      "(3534,)\n",
      "(23343,)\n",
      "(3534,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVYcq7gu1GXE"
   },
   "source": [
    "Initialising text classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEtNUpxf00JG",
    "outputId": "d445543c-46d6-4d88-f5aa-462a5abb00cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/bryankoh/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise spacy \n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Get nltk set of english words\n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zRJ5V4oT1BTK"
   },
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Set nltk vocab\n",
    "vocab = set(nltk.corpus.words.words())\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = nlp(sentence)\n",
    "\n",
    "    # Lemmatizing each token\n",
    "    mytokens = [ token.lemma_ for token in mytokens if token.lemma_ in vocab]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ token for token in mytokens if token not in stop_words ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHgGTDsa1Y0N"
   },
   "source": [
    "Helper functions to test various machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TQ61e4Pi1Tf1"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Insert document-term matrices, y-values and model\n",
    "def test_nb_model(X_train_dtm, y_train, X_test_dtm, y_test, return_model = False):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred = nb.predict(X_test_dtm)\n",
    "    train_acc = metrics.accuracy_score(y_train, nb.predict(X_train_dtm))\n",
    "    test_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print('Training accuracy: ', train_acc)\n",
    "    print('Test accuracy: ', test_acc)\n",
    "    if return_model:\n",
    "      return train_acc, test_acc, nb\n",
    "    else:\n",
    "      return train_acc, test_acc\n",
    "  \n",
    "def test_lr_model(X_train_dtm, y_train, X_test_dtm, y_test, return_model = False):\n",
    "    lr = LogisticRegression(random_state = 0)\n",
    "    lr.fit(X_train_dtm, y_train)\n",
    "    y_pred = lr.predict(X_test_dtm)\n",
    "    train_acc = metrics.accuracy_score(y_train, lr.predict(X_train_dtm))\n",
    "    test_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print('Training accuracy: ', train_acc)\n",
    "    print('Test accuracy: ', test_acc)\n",
    "    if return_model:\n",
    "      return train_acc, test_acc, lr\n",
    "    else:\n",
    "      return train_acc, test_acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGC5R0NRalYX"
   },
   "source": [
    "# Approach 1: CountVectorizer/TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2FAsEPz11vc"
   },
   "source": [
    "Parameter tuning for **CountVectorizer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2unVfs5H7oMk"
   },
   "outputs": [],
   "source": [
    "n_grams = [(1,1)]\n",
    "max_df = [0.6, 0.8, 1.0]\n",
    "max_features = ['default', 500, 750, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AkKaDo5H9iqv"
   },
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Ln-gUNoy81kj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def search_cv_best_params():\n",
    "  iteration = 1\n",
    "  for i in n_grams:\n",
    "    for j in max_df:\n",
    "      for k in max_features:\n",
    "        print(\"Iteration \" + str(iteration))\n",
    "        print(\"n_grams: \" + str(i))\n",
    "        print(\"max_df: \" + str(j))\n",
    "        print(\"max_features: \" + str(k))\n",
    "        if k == 'default':\n",
    "          cv = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=i, max_df = j)\n",
    "        else:\n",
    "          cv = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=i, max_df = j, max_features = k)\n",
    "\n",
    "        train_dtm = cv.fit_transform(X_train)\n",
    "        X_train_dtm = pd.DataFrame(train_dtm.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "        test_dtm = cv.transform(X_test)\n",
    "        X_test_dtm = pd.DataFrame(test_dtm.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "        print('\\n')\n",
    "        nb_train, nb_test = test_nb_model(X_train_dtm, y_train, X_test_dtm, y_test)\n",
    "\n",
    "        hash = str(i) + ', ' + str(j) + ', ' + str(k)\n",
    "        scores[hash] = [nb_train, nb_test]\n",
    "        print(\"--------------------\\n\")\n",
    "        iteration += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Grom3r0eYoFF",
    "outputId": "151235a2-304a-4fd6-b929-c17e602b0473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.6\n",
      "max_features: default\n",
      "\n",
      "\n",
      "Training accuracy:  0.7446343657627554\n",
      "Test accuracy:  0.631578947368421\n",
      "--------------------\n",
      "\n",
      "Iteration 2\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.6\n",
      "max_features: 500\n",
      "\n",
      "\n",
      "Training accuracy:  0.6413914235530994\n",
      "Test accuracy:  0.6247877758913413\n",
      "--------------------\n",
      "\n",
      "Iteration 3\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.6\n",
      "max_features: 750\n",
      "\n",
      "\n",
      "Training accuracy:  0.6575847149038255\n",
      "Test accuracy:  0.634974533106961\n",
      "--------------------\n",
      "\n",
      "Iteration 4\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.6\n",
      "max_features: 1000\n",
      "\n",
      "\n",
      "Training accuracy:  0.6668380242470976\n",
      "Test accuracy:  0.6361063950198076\n",
      "--------------------\n",
      "\n",
      "Iteration 5\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.8\n",
      "max_features: default\n",
      "\n",
      "\n",
      "Training accuracy:  0.7446343657627554\n",
      "Test accuracy:  0.631578947368421\n",
      "--------------------\n",
      "\n",
      "Iteration 6\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.8\n",
      "max_features: 500\n",
      "\n",
      "\n",
      "Training accuracy:  0.6413914235530994\n",
      "Test accuracy:  0.6247877758913413\n",
      "--------------------\n",
      "\n",
      "Iteration 7\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.8\n",
      "max_features: 750\n",
      "\n",
      "\n",
      "Training accuracy:  0.6575847149038255\n",
      "Test accuracy:  0.634974533106961\n",
      "--------------------\n",
      "\n",
      "Iteration 8\n",
      "n_grams: (1, 1)\n",
      "max_df: 0.8\n",
      "max_features: 1000\n",
      "\n",
      "\n",
      "Training accuracy:  0.6668380242470976\n",
      "Test accuracy:  0.6361063950198076\n",
      "--------------------\n",
      "\n",
      "Iteration 9\n",
      "n_grams: (1, 1)\n",
      "max_df: 1.0\n",
      "max_features: default\n",
      "\n",
      "\n",
      "Training accuracy:  0.7446343657627554\n",
      "Test accuracy:  0.631578947368421\n",
      "--------------------\n",
      "\n",
      "Iteration 10\n",
      "n_grams: (1, 1)\n",
      "max_df: 1.0\n",
      "max_features: 500\n",
      "\n",
      "\n",
      "Training accuracy:  0.6413914235530994\n",
      "Test accuracy:  0.6247877758913413\n",
      "--------------------\n",
      "\n",
      "Iteration 11\n",
      "n_grams: (1, 1)\n",
      "max_df: 1.0\n",
      "max_features: 750\n",
      "\n",
      "\n",
      "Training accuracy:  0.6575847149038255\n",
      "Test accuracy:  0.634974533106961\n",
      "--------------------\n",
      "\n",
      "Iteration 12\n",
      "n_grams: (1, 1)\n",
      "max_df: 1.0\n",
      "max_features: 1000\n",
      "\n",
      "\n",
      "Training accuracy:  0.6668380242470976\n",
      "Test accuracy:  0.6361063950198076\n",
      "--------------------\n",
      "\n",
      "Iteration 13\n",
      "n_grams: (1, 2)\n",
      "max_df: 0.6\n",
      "max_features: default\n"
     ]
    }
   ],
   "source": [
    "search_best_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSFPpRdNy8W6"
   },
   "source": [
    "Generally default parameters for all, max_df = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kblw7a6G3Dkf"
   },
   "source": [
    "Parameter tuning for **TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Hx-S-f_M3bM1"
   },
   "outputs": [],
   "source": [
    "tfidf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "x7dmPCgL3FoQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def search_tfidf_best_params():\n",
    "  iteration = 1\n",
    "  for i in n_grams:\n",
    "    for j in max_df:\n",
    "      for k in max_features:\n",
    "        print(\"Iteration \" + str(iteration))\n",
    "        print(\"max_df: \" + str(j))\n",
    "        print(\"max_features: \" + str(k))\n",
    "        if k == 'default':\n",
    "          cv = TfidfVectorizer(tokenizer = spacy_tokenizer, max_df = j)\n",
    "        else:\n",
    "          cv = TfidfVectorizer(tokenizer = spacy_tokenizer, max_df = j, max_features = k)\n",
    "\n",
    "        train_dtm = cv.fit_transform(X_train)\n",
    "        X_train_dtm = pd.DataFrame(train_dtm.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "        test_dtm = cv.transform(X_test)\n",
    "        X_test_dtm = pd.DataFrame(test_dtm.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "        print('\\n')\n",
    "        nb_train, nb_test = test_nb_model(X_train_dtm, y_train, X_test_dtm, y_test)\n",
    "\n",
    "        hash = str(i) + ', ' + str(j) + ', ' + str(k)\n",
    "        tfidf[hash] = [nb_train, nb_test]\n",
    "        print(\"--------------------\\n\")\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOfWwDx83_H6",
    "outputId": "96992590-f1b2-4ba6-de8f-31d8d2510c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "max_df: 0.6\n",
      "max_features: default\n",
      "\n",
      "\n",
      "Training accuracy:  0.7478044810007283\n",
      "Test accuracy:  0.6327108092812677\n",
      "--------------------\n",
      "\n",
      "Iteration 2\n",
      "max_df: 0.6\n",
      "max_features: 500\n",
      "\n",
      "\n",
      "Training accuracy:  0.642119693269931\n",
      "Test accuracy:  0.6267685342388228\n",
      "--------------------\n",
      "\n",
      "Iteration 3\n",
      "max_df: 0.6\n",
      "max_features: 750\n",
      "\n",
      "\n",
      "Training accuracy:  0.6582273058304416\n",
      "Test accuracy:  0.6329937747594794\n",
      "--------------------\n",
      "\n",
      "Iteration 4\n",
      "max_df: 0.6\n",
      "max_features: 1000\n",
      "\n",
      "\n",
      "Training accuracy:  0.6683374030758685\n",
      "Test accuracy:  0.6346915676287493\n",
      "--------------------\n",
      "\n",
      "Iteration 5\n",
      "max_df: 0.8\n",
      "max_features: default\n",
      "\n",
      "\n",
      "Training accuracy:  0.7478044810007283\n",
      "Test accuracy:  0.6327108092812677\n",
      "--------------------\n",
      "\n",
      "Iteration 6\n",
      "max_df: 0.8\n",
      "max_features: 500\n",
      "\n",
      "\n",
      "Training accuracy:  0.642119693269931\n",
      "Test accuracy:  0.6267685342388228\n",
      "--------------------\n",
      "\n",
      "Iteration 7\n",
      "max_df: 0.8\n",
      "max_features: 750\n",
      "\n",
      "\n",
      "Training accuracy:  0.6582273058304416\n",
      "Test accuracy:  0.6329937747594794\n",
      "--------------------\n",
      "\n",
      "Iteration 8\n",
      "max_df: 0.8\n",
      "max_features: 1000\n",
      "\n",
      "\n",
      "Training accuracy:  0.6683374030758685\n",
      "Test accuracy:  0.6346915676287493\n",
      "--------------------\n",
      "\n",
      "Iteration 9\n",
      "max_df: 1.0\n",
      "max_features: default\n",
      "\n",
      "\n",
      "Training accuracy:  0.7478044810007283\n",
      "Test accuracy:  0.6327108092812677\n",
      "--------------------\n",
      "\n",
      "Iteration 10\n",
      "max_df: 1.0\n",
      "max_features: 500\n",
      "\n",
      "\n",
      "Training accuracy:  0.642119693269931\n",
      "Test accuracy:  0.6267685342388228\n",
      "--------------------\n",
      "\n",
      "Iteration 11\n",
      "max_df: 1.0\n",
      "max_features: 750\n",
      "\n",
      "\n",
      "Training accuracy:  0.6582273058304416\n",
      "Test accuracy:  0.6329937747594794\n",
      "--------------------\n",
      "\n",
      "Iteration 12\n",
      "max_df: 1.0\n",
      "max_features: 1000\n",
      "\n",
      "\n",
      "Training accuracy:  0.6683374030758685\n",
      "Test accuracy:  0.6346915676287493\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_tfidf_best_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIIgTGr5Kmg7"
   },
   "source": [
    "Best is also max_df = 0.6, with default measures. TFIDF is slightly better than CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LQDbI_2NUD0"
   },
   "source": [
    "# Final sentiment model: TFIDF(tokenizer = spacy_tokenizer, max_df = 0.6) using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ztlMCYcLYYS",
    "outputId": "d7290467-221b-4f32-df6c-b3d6f13565a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.776635393908238\n",
      "Test accuracy:  0.6977928692699491\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = spacy_tokenizer, max_df = 0.6)\n",
    "\n",
    "train_dtm = tfidf.fit_transform(X_train)\n",
    "X_train_dtm = pd.DataFrame(train_dtm.toarray(), columns=tfidf.get_feature_names())\n",
    "\n",
    "test_dtm = tfidf.transform(X_test)\n",
    "X_test_dtm = pd.DataFrame(test_dtm.toarray(), columns=tfidf.get_feature_names())\n",
    "\n",
    "nb_train, nb_test, lr = test_lr_model(X_train_dtm, y_train, X_test_dtm, y_test, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "-6oqQivUNj5f",
    "outputId": "80e220f1-bdcc-45b8-cec2-b5533cb739e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>tcooutlinks</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>...</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>media</th>\n",
       "      <th>retweetedTweet</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/lundp/status/1547135712536...</td>\n",
       "      <td>2012-01-04 23:59:24+00:00</td>\n",
       "      <td>Trying new iSkin protector on MacBook Pro. And...</td>\n",
       "      <td>154713571253686272</td>\n",
       "      <td>https://twitter.com/lundp</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154713571253686272</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://itunes.apple.com/us/app/twitte...</td>\n",
       "      <td>http://itunes.apple.com/us/app/twitter/id40978...</td>\n",
       "      <td>Twitter for Mac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://twitter.com/JayDCooke/status/154713564...</td>\n",
       "      <td>2012-01-04 23:59:22+00:00</td>\n",
       "      <td>I'm ready to get on the #MacBook</td>\n",
       "      <td>154713564031090689</td>\n",
       "      <td>https://twitter.com/JayDCooke</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154713564031090689</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://twitter.com/Semhar/status/154713498935...</td>\n",
       "      <td>2012-01-04 23:59:07+00:00</td>\n",
       "      <td>Syncing my entire life. All my personal &amp; DAWN...</td>\n",
       "      <td>154713498935496704</td>\n",
       "      <td>https://twitter.com/Semhar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154713498935496704</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>http://twitter.com</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  \\\n",
       "0           0  https://twitter.com/lundp/status/1547135712536...   \n",
       "1           1  https://twitter.com/JayDCooke/status/154713564...   \n",
       "2           2  https://twitter.com/Semhar/status/154713498935...   \n",
       "\n",
       "                        date  \\\n",
       "0  2012-01-04 23:59:24+00:00   \n",
       "1  2012-01-04 23:59:22+00:00   \n",
       "2  2012-01-04 23:59:07+00:00   \n",
       "\n",
       "                                             content                  id  \\\n",
       "0  Trying new iSkin protector on MacBook Pro. And...  154713571253686272   \n",
       "1                   I'm ready to get on the #MacBook  154713564031090689   \n",
       "2  Syncing my entire life. All my personal & DAWN...  154713498935496704   \n",
       "\n",
       "                            user outlinks tcooutlinks  replyCount  \\\n",
       "0      https://twitter.com/lundp       []          []           0   \n",
       "1  https://twitter.com/JayDCooke       []          []           0   \n",
       "2     https://twitter.com/Semhar       []          []           0   \n",
       "\n",
       "   retweetCount  ...      conversationId  lang  \\\n",
       "0             0  ...  154713571253686272    en   \n",
       "1             0  ...  154713564031090689    en   \n",
       "2             0  ...  154713498935496704    en   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://itunes.apple.com/us/app/twitte...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "\n",
       "                                           sourceUrl         sourceLabel  \\\n",
       "0  http://itunes.apple.com/us/app/twitter/id40978...     Twitter for Mac   \n",
       "1                 http://twitter.com/download/iphone  Twitter for iPhone   \n",
       "2                                 http://twitter.com  Twitter Web Client   \n",
       "\n",
       "  media retweetedTweet  quotedTweet  mentionedUsers  device  \n",
       "0   NaN            NaN          NaN             NaN     mac  \n",
       "1   NaN            NaN          NaN             NaN     mac  \n",
       "2   NaN            NaN          NaN             NaN     mac  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('./tweets.csv')\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce1VVjE3SN5j",
    "outputId": "5dbef2f3-012e-4377-957b-ec31c2ef203e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61440, 22)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qfKeennFP39W"
   },
   "outputs": [],
   "source": [
    "X_tweets_dtm = tfidf.transform(tweets.content)\n",
    "X_tweets_dtm = pd.DataFrame(X_tweets_dtm.toarray(), columns=tfidf.get_feature_names())\n",
    "tweets_pred = lr.predict(X_tweets_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Q9DIKpJXpvh",
    "outputId": "1609f213-499e-4eaa-e277-b7dd0a691a40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61440,)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-B10o8uPXsHC"
   },
   "outputs": [],
   "source": [
    "tweets['sentiment'] = tweets_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GCjkcpKmXxdV"
   },
   "outputs": [],
   "source": [
    "tweets.to_csv('gdrive/My Drive/BT4222/data/tweets_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('roberta', 'roberta-base', num_labels=3, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23343,)\n",
      "(3534,)\n",
      "(23343,)\n",
      "(3534,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = pd.concat([X_train, y_train], axis=1)\n",
    "bert_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23968</th>\n",
       "      <td>playing with image</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13037</th>\n",
       "      <td>if i ran the mile to mcdonalds and ran the mil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26167</th>\n",
       "      <td>i knew that, jus givin u a hard time hehe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "23968                                 playing with image          0\n",
       "13037  if i ran the mile to mcdonalds and ran the mil...          0\n",
       "26167          i knew that, jus givin u a hard time hehe          0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert model target must be > 0\n",
    "bert_train['sentiment'] = bert_train['sentiment'].map({-1: 0, 0: 1, 1: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23968</th>\n",
       "      <td>playing with image</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13037</th>\n",
       "      <td>if i ran the mile to mcdonalds and ran the mil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26167</th>\n",
       "      <td>i knew that, jus givin u a hard time hehe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "23968                                 playing with image          1\n",
       "13037  if i ran the mile to mcdonalds and ran the mil...          1\n",
       "26167          i knew that, jus givin u a hard time hehe          1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0cf13f048d4e0480474200d03b8994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c62ed8b4154b5ba1f2ff9e958a9368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0150863c742a2a822ac106a74e7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 1', max=2918.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2918, 0.635360029280298)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(bert_train, output_dir='./bert_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test['sentiment'] = bert_test['sentiment'].map({-1: 0, 0: 1, 1: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7582f6b14d0449618ecd04f183d40327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=2918.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_result, training_model_outputs, training_wrong_predictions = model.eval_model(bert_train, acc=sklearn.metrics.accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840337574433449"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training accuracy\n",
    "training_result['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edd0c7a4d1b4395982ef6b221cf57a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=442.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "result, model_outputs, wrong_predictions = model.eval_model(bert_test, acc=sklearn.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcc': 0.6787822693614097,\n",
       " 'acc': 0.7857951329937748,\n",
       " 'eval_loss': 0.5457427991191726}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing accuracy\n",
    "result['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = tweets.content.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e240cf962047c6a9dcfa6102e88212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7680.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_predictions, _ = model.predict(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['sentiment'] = bert_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map back to -1, 0 and 1\n",
    "tweets['sentiment'] = tweets['sentiment'].map({0: -1, 1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('./tweets_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving down models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Save BERT model\n",
    "with open('bert.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
